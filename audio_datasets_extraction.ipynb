{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkQXRJM1rKoifHOzQulqxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deviprasanna-17/audio_analysis_infysp_group1/blob/main/audio_datasets_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Ba3CNphzQl"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# INSTALL DEPENDENCIES\n",
        "# ===============================\n",
        "!pip install librosa soundfile noisereduce webrtcvad pydub --quiet\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "import webrtcvad\n",
        "import struct\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# ===============================\n",
        "# DATASET LOADING\n",
        "# ===============================\n",
        "def load_dataset(path, extensions=(\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
        "    audio_files = [\n",
        "        os.path.join(path, f)\n",
        "        for f in os.listdir(path)\n",
        "        if f.lower().endswith(extensions)\n",
        "    ]\n",
        "    return audio_files\n",
        "\n",
        "# ===============================\n",
        "# PREPROCESSING STEPS\n",
        "# ===============================\n",
        "\n",
        "# 1. Load + Resample to 16kHz + Mono\n",
        "def load_and_resample(path, target_sr=16000):\n",
        "    audio, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "    return audio, target_sr\n",
        "\n",
        "# 2. Normalize audio\n",
        "def normalize(audio):\n",
        "    return audio / (np.max(np.abs(audio)) + 1e-9)\n",
        "\n",
        "# 3. Noise reduction\n",
        "def denoise(audio, sr):\n",
        "    return nr.reduce_noise(y=audio, sr=sr)\n",
        "\n",
        "# 4. Silence removal\n",
        "def remove_silence(audio, sr):\n",
        "    trimmed, _ = librosa.effects.trim(audio, top_db=25)\n",
        "    return trimmed\n",
        "\n",
        "# 5. Voice Activity Detection (WebRTC VAD)\n",
        "vad = webrtcvad.Vad(2)  # aggressiveness: 0–3\n",
        "\n",
        "def frame_generator(audio, sr, frame_ms=30):\n",
        "    frame_len = int(sr * frame_ms / 1000)\n",
        "    for i in range(0, len(audio), frame_len):\n",
        "        chunk = audio[i:i+frame_len]\n",
        "        if len(chunk) < frame_len:\n",
        "            break\n",
        "        pcm = struct.pack(\"%dh\" % frame_len, *(chunk * 32768).astype('int16'))\n",
        "        yield pcm, i, i+frame_len\n",
        "\n",
        "def apply_vad(audio, sr):\n",
        "    voiced_audio = []\n",
        "    for pcm, start, end in frame_generator(audio, sr):\n",
        "        if vad.is_speech(pcm, sr):\n",
        "            voiced_audio.extend(audio[start:end])\n",
        "    return np.array(voiced_audio)\n",
        "\n",
        "# ===============================\n",
        "# FULL PIPELINE\n",
        "# ===============================\n",
        "def preprocess_audio(path):\n",
        "    audio, sr = load_and_resample(path)\n",
        "\n",
        "    audio = normalize(audio)\n",
        "    audio = denoise(audio, sr)\n",
        "    audio = remove_silence(audio, sr)\n",
        "    audio = apply_vad(audio, sr)\n",
        "\n",
        "    return audio, sr\n",
        "\n",
        "# ===============================\n",
        "# PROCESS ENTIRE DATASET\n",
        "# ===============================\n",
        "raw_dir = \"/content/raw_audio\"       # ← Put your folder of audio files here\n",
        "processed_dir = \"/content/processed_audio\"\n",
        "os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "audio_paths = load_dataset(raw_dir)\n",
        "\n",
        "print(\"Found\", len(audio_paths), \"audio files.\")\n",
        "\n",
        "for path in audio_paths:\n",
        "    print(\"Processing:\", path)\n",
        "    audio, sr = preprocess_audio(path)\n",
        "\n",
        "    out_name = os.path.basename(path).rsplit(\".\", 1)[0] + \"_clean.wav\"\n",
        "    out_path = os.path.join(processed_dir, out_name)\n",
        "\n",
        "    sf.write(out_path, audio, sr)\n",
        "\n",
        "print(\"Processing complete! Cleaned files saved to:\", processed_dir)\n"
      ]
    }
  ]
}